{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/up1512001/1657aac9693accd561be484a1a7c0d3a/video-intelegence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1oJZWk7Lqfym",
    "outputId": "bfdda1e8-ca7f-4a0a-8b87-7e932a44121e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SmZtfHxes-X0"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array,load_img\n",
    "import numpy as np\n",
    "import glob\n",
    "import os \n",
    "import cv2\n",
    "\n",
    "from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_oUYecUtyqB"
   },
   "outputs": [],
   "source": [
    "store_image=[]\n",
    "train_path='/content/drive/MyDrive/Colab Notebooks/train_video'\n",
    "fps=5\n",
    "train_videos=os.listdir(train_path)\n",
    "# print(train_videos)\n",
    "train_images_path=train_path+'/frames'\n",
    "os.makedirs(train_images_path)\n",
    "# print(os.listdir(train_images_path))\n",
    "def store_inarray(image_path):\n",
    "    image=load_img(image_path)\n",
    "    image=img_to_array(image)\n",
    "    image=cv2.resize(image, (227,227), interpolation = cv2.INTER_AREA)\n",
    "    gray=0.2989*image[:,:,0]+0.5870*image[:,:,1]+0.1140*image[:,:,2]\n",
    "    store_image.append(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nkALssUuCsy"
   },
   "outputs": [],
   "source": [
    "# from logging import currentframe\n",
    "currentframe=0\n",
    "for video in train_videos:\n",
    "    cap = cv2.VideoCapture('{}/{}'.format(train_path,video))\n",
    "    while(True):\n",
    "      ret,frame = cap.read()\n",
    "      if ret:\n",
    "        x = '/content/train dir/'+str(currentframe)+'.jpg'\n",
    "        # print(x)\n",
    "        cv2.imwrite(x,frame)\n",
    "        currentframe+=1\n",
    "      else:\n",
    "        break\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sVgT8UsFvegc"
   },
   "outputs": [],
   "source": [
    "train_images_path = '/content/train dir'\n",
    "images=os.listdir(train_images_path)\n",
    "# images.remove('.ipynb_checkpoints')\n",
    "  # print(images)\n",
    "for image in images:\n",
    "    image_path=train_images_path + '/' + image\n",
    "    store_inarray(image_path)\n",
    "    # print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "p7RWJTVvvtwF"
   },
   "outputs": [],
   "source": [
    "# print(os.listdir('/content/train dir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "P4joM-XWwMnS"
   },
   "outputs": [],
   "source": [
    "store_image=np.array(store_image)\n",
    "a,b,c=store_image.shape\n",
    "# print(store_image.shape)\n",
    "store_image.resize(b,c,a)\n",
    "store_image=(store_image-store_image.mean())/(store_image.std())\n",
    "store_image=np.clip(store_image,0,1)\n",
    "np.save('training.npy',store_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "R3TeBO-SwQXq"
   },
   "outputs": [],
   "source": [
    "stae_model=Sequential()\n",
    "\n",
    "stae_model.add(Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',input_shape=(227,227,10,1),activation='tanh'))\n",
    "stae_model.add(Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
    "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True))\n",
    "stae_model.add(ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True))\n",
    "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,return_sequences=True, padding='same',dropout=0.5))\n",
    "stae_model.add(Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
    "stae_model.add(Conv3DTranspose(filters=1,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',activation='tanh'))\n",
    "\n",
    "stae_model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRG0KpM8wr-r",
    "outputId": "365deffd-5bfa-4a3f-98ee-45e63a836f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1532/1532 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.7183WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1532/1532 [==============================] - 6123s 4s/step - loss: 0.0838 - accuracy: 0.7183\n",
      "Epoch 2/5\n",
      "1532/1532 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.7374WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1532/1532 [==============================] - 7186s 5s/step - loss: 0.0690 - accuracy: 0.7374\n",
      "Epoch 3/5\n",
      "1532/1532 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.7380WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1532/1532 [==============================] - 7417s 5s/step - loss: 0.0683 - accuracy: 0.7380\n",
      "Epoch 4/5\n",
      "1532/1532 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.7650WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1532/1532 [==============================] - 7334s 5s/step - loss: 0.0385 - accuracy: 0.7650\n",
      "Epoch 5/5\n",
      "1532/1532 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.7758WARNING:tensorflow:Can save best model only with mean_squared_error available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1532/1532 [==============================] - 7315s 5s/step - loss: 0.0287 - accuracy: 0.7758\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "training_data=np.load('training.npy')\n",
    "frames=training_data.shape[2]\n",
    "frames=frames-frames%10\n",
    "\n",
    "training_data=training_data[:,:,:frames]\n",
    "training_data=training_data.reshape(-1,227,227,10)\n",
    "training_data=np.expand_dims(training_data,axis=4)\n",
    "target_data=training_data.copy()\n",
    "\n",
    "epochs=5\n",
    "batch_size=1\n",
    "\n",
    "callback_save = ModelCheckpoint(\"saved_model.h5\", monitor=\"mean_squared_error\", save_best_only=True)\n",
    "\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "stae_model.fit(training_data,target_data, batch_size=batch_size, epochs=epochs, callbacks = [callback_save,callback_early_stopping])\n",
    "stae_model.save(\"saved_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kQdkktVuwuUN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8yOKUdGw4Bx1"
   },
   "outputs": [],
   "source": [
    "def mean_squared_loss(x1,x2):\n",
    "    difference=x1-x2\n",
    "    a,b,c,d,e=difference.shape\n",
    "    n_samples=a*b*c*d*e\n",
    "    sq_difference=difference**2\n",
    "    Sum=sq_difference.sum()\n",
    "    distance=np.sqrt(Sum)\n",
    "    mean_distance=distance/n_samples\n",
    "    return mean_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPGFll7f4EIo",
    "outputId": "72894be2-d1ee-4c44-bd2e-771f0af7a741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"saved_model.h5\")\n",
    "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Colab Notebooks/train_video_6th_project/test/09.avi\")\n",
    "print(cap.isOpened())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Eyae6YX66Fm0"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "MOBfRaAZ4H36",
    "outputId": "f5be0837-1bc1-41c5-88d6-a9a436f157bb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-753767ca696d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimagedump\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    imagedump=[]\n",
    "    ret,frame=cap.read()\n",
    "    for i in range(10):\n",
    "        ret,frame=cap.read()\n",
    "        image = imutils.resize(frame,width=700,height=600)\n",
    "        frame=cv2.resize(frame, (227,227), interpolation = cv2.INTER_AREA)\n",
    "        gray=0.2989*frame[:,:,0]+0.5870*frame[:,:,1]+0.1140*frame[:,:,2]\n",
    "        gray=(gray-gray.mean())/gray.std()\n",
    "        gray=np.clip(gray,0,1)\n",
    "        imagedump.append(gray)\n",
    "    imagedump=np.array(imagedump)\n",
    "    imagedump.resize(227,227,10)\n",
    "    imagedump=np.expand_dims(imagedump,axis=0)\n",
    "    imagedump=np.expand_dims(imagedump,axis=4)\n",
    "    output=model.predict(imagedump)\n",
    "    loss=mean_squared_loss(imagedump,output)\n",
    "    if frame.any()==None:\n",
    "        print(\"none\")\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "    if loss>0.00068:\n",
    "        print('Abnormal Event Detected')\n",
    "        cv2.putText(image,\"Abnormal Event\",(100,80),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),4)\n",
    "    cv2_imshow(image)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvDvzAX6535p",
    "outputId": "84e4d9a2-bb1c-4ab3-f48d-aec9c7e91fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zA67LAJH9bwJ",
    "outputId": "ffcbad17-61a3-48a8-b529-cf0e94b65c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
     ]
    }
   ],
   "source": [
    "!ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yC3uuXYr9pD1",
    "outputId": "10088097-ecfd-410b-e620-f9e4a080c100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f12694a0650>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Create a new model instance\n",
    "# model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Evaluate the model\n",
    "# loss, acc = model.evaluate(, test_labels, verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "qHJ_o4j5_ao7",
    "outputId": "aee41814-86f9-4030-af26-196871b8876a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a9712b53aa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rccL_PPxHTMD",
    "outputId": "fcf1fd59-83b5-4531-ae34-237bd3f252de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow' from '/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtTHzU0LQQLVh5qII/0iKC",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Z8NPH9Kw6xUyHkgO69NR4jjwiITVD8Jq",
   "name": "video intelegence.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
